<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE topic PUBLIC "-//OASIS//DTD DITA Topic//EN" "topic.dtd">
<topic id="topic_isj_khw_sbs" otherprops="pivotal">
  <title>Migrating Data with gpcopy</title>
  <shortdesc>This topic describes how to use the <codeph>gpcopy</codeph> utility to transfer data
    between databases in different Greenplum Database clusters.</shortdesc>
  <body>
    <p><codeph>gpcopy</codeph> is a high-performance utility that can copy metadata and data from
      one Greenplum database to another Greenplum database. You can migrate the entire contents of a
      database, or just selected tables. The source and destination databases must be in different
      clusters, and the clusters can have different Greenplum Database versions. For example, you
      can use <codeph>gpcopy</codeph> to migrate data from a version 4.x Greenplum Database to
      version 5.x.</p>
    <p>The <codeph>gpcopy</codeph> interface includes options to transfer one or more full
      databases, or one or more database tables. A full database transfer includes the database
      schema, table data, indexes, views, roles, user-defined functions, resource queues, and
      resource groups. If a copied table or database does not exist in the destination cluster,
        <codeph>gpcopy</codeph> creates it automatically.</p>
    <p>Configuration files, including <codeph>postgres.conf</codeph> and
        <codeph>pg_hba.conf</codeph>, must be transferred manually by an administrator. Extensions
      installed in the database with <codeph>gppkg</codeph>, such as MADlib and programming language
      extensions, must be installed in the destination database by an administrator. </p>
    <p><codeph>gpcopy</codeph> uses many of the same command-line options as the earlier
        <codeph>gptransfer</codeph> utility. <codeph>gpcopy</codeph> provides several improvements
      as compared to <codeph>gptransfer</codeph>:<ul id="ul_ibs_vsp_zdb">
        <li><codeph>gpcopy</codeph> performs significantly faster than <codeph>gptransfer</codeph>
          when copying large amounts of data.</li>
        <li><codeph>gpcopy</codeph> provides more detailed reporting and summary information about
          all aspects of the copy operation.</li>
        <li>
          <p><codeph>gpcopy</codeph> allows the source table data to change while the data is being
            copied. A lock is not acquired on the source table when data is copied. </p>
        </li>
        <li>The <codeph>gpcopy</codeph> utility includes the
            <codeph>--truncate-source-after</codeph> option to help migrate data from one Pivotal
          Greenplum Database system to another on the same hardware, requiring minimal free space
          available.</li>
      </ul></p></body>
    <topic id="topic_psq_dsp_zdb">
    <title>Prerequisites</title>
    <body>
      <p>The source and destination Greenplum Database systems must already exist, have network
        access between all hosts, and have master host and primary segment hosts in both systems.
        Each system must be configured with the same number of segments.</p>
      <p><codeph>gpcopy</codeph> is dependent on the <codeph>pg_dump</codeph>,
          <codeph>pg_dumpall</codeph>, and <codeph>psql</codeph> utilities installed with Greenplum
        Database. In most cases, you run <codeph>gpcopy</codeph> from a Greenplum Database cluster,
        so the dependencies are automatically met. If you run <codeph>gpcopy</codeph> on a remote
        server, such as an ETL system, you manually copy the <codeph>gpcopy</codeph> utility as well
        as <codeph>pg_dump</codeph>, <codeph>pg_dumpall</codeph>, and <codeph>psql</codeph> to that
        system.</p>
      <p><codeph>gpcopy</codeph> supports migrating data from a Greenplum Database 4.3.26 or later
        cluster to a Greenplum Database 5.9 or later cluster. However Greenplum Database 4.3.26 and
        later do not include the actual <codeph>gpcopy</codeph> utility. You must manually copy the
          <codeph>gpcopy</codeph> utility from your version 5.9 or later cluster into the older
        version cluster to migrate data.. For
        example:<codeblock>$ cp /usr/local/greenplum-db-5.8.0/bin/gpcopy /usr/local/greenplum-db-4.3.26.0/bin/</codeblock></p>
    </body>
  </topic>
    <topic id="topic_qwl_2rp_zdb">
      <title>Limitations for the Source and Destination Systems</title>
      <body>
      <p><codeph>gpcopy</codeph> cannot copy data from one database to another in the same Greenplum
        Database system. The destination system must be a separate Greenplum Database cluster.</p>
        <p dir="ltr" id="docs-internal-guid-872b07d9-60bd-1131-d5a6-3fb4dc225771">The
          <codeph>gpcopy</codeph> utility supports copying only between source and destination
        Greenplum Database systems with the same number of segments. If you need to transfer data to
        a Greenplum Database system having a different number of segments, you must use
          <codeph>gptransfer</codeph> instead. See <xref href="gptransfer.xml#topic_gptransfer"
        />.</p>
        <p>If you are copying data between Greenplum Database clusters having different versions,
        each cluster must have <codeph>gpcopy</codeph> installed locally. <codeph>gpcopy</codeph> is
        installed with Pivotal Greenplum Database starting with versions 5.9.0 and 4.3.26.0.</p>
        <p><codeph>gpcopy</codeph> transfers data from user databases only; the
            <codeph>postgres</codeph>, <codeph>template0</codeph>, and <codeph>template1</codeph>
          databases cannot be transferred. Administrators must transfer configuration files manually
          and install extensions into the destination database with <codeph>gppkg</codeph>.</p>
        <p><codeph>gpcopy</codeph> cannot copy a row that is larger than 1GB in size.</p>
        <p>When transferring data between databases, you can run only one instance of
          <codeph>gpcopy</codeph> at a time.  Running multiple, concurrent instances of
          <codeph>gpcopy</codeph> is not supported.</p>
      </body>
    </topic>
  <topic id="topic_ekp_rmp_zdb">
    <title>Performing a Basic Copy Operation</title>
    <body>
      <p>This example <codeph>gpcopy</codeph> command specifies the <codeph>--full</codeph> option
        to perform a migration of a Greenplum Database source system to a destination system. A
        migration copies all database objects including tables, indexes, views, roles, functions,
        user defined types (UDT), resource queues, and resource groups for all user defined
        databases. </p>
      <codeblock>gpcopy --source-host mytest --source-port 1234 --source-user gpuser \
    --dest-host demohost --dest-port 1234 --dest-user gpuser \
    --full --drop --validate count</codeblock>
      <p>When performing the copy, the utility drops tables in the destination database
          (<codeph>--drop</codeph> option) and uses the row count of the source and destination
        tables to validate the data transfer (<codeph>--validate count</codeph> option). The other
          <codeph>gpcopy</codeph> options specify the source and destination Greenplum Database
        system master hosts, ports, and the User ID to use to connect to the Greenplum Database
        systems.</p>
      <p>See the <codeph>gpcopy</codeph> utility <ph otherprops="op-print">in the <cite>Greenplum
            Database Utility Guide</cite>
        </ph>for complete syntax and usage information. </p>
    </body>
  </topic>
    <topic id="topic_ay1_frp_zdb">
      <title>Configuring Parallel Jobs</title>
      <body>
        <p>The degree of parallelism when running <codeph>gpcopy</codeph> is determined the option
          <codeph>--jobs</codeph>. The option controls the number processes that
          <codeph>gpcopy</codeph> runs in parallel. The default is 4. The range is from 1 to 64. </p>
      <p>The <codeph>--jobs</codeph> value, <varname>n</varname>, produces
            <codeph>2*<varname>n</varname>+1</codeph> database connections. For example, the default
          <codeph>--jobs</codeph> value of 4 creates 9 connections.</p>
        <p>If you increase this option, ensure that the Greenplum Database systems are configured
        with a sufficient maximum concurrent connection value to accommodate the
          <codeph>gpcopy</codeph> connections and any other concurrent connections (such as user
        connections) that you require. See the Greenplum Database server configuration parameter
          <codeph>max_connections</codeph>.</p>
      </body>
    </topic>
    <topic id="topic_nd3_2sp_zdb">
    <title>Validating Copied Data</title>
    <body>
      <p>By default, <codeph>gpcopy</codeph> does not validate the data transferred. You can request
        validation using the <codeph>--validate=<i>type</i></codeph> option. The validation
          <i>type</i> can be one of the following:<ul id="ul_hf1_k21_xdb">
          <li><codeph>count</codeph> - compares the row counts between the source and destination
            tables.</li>
          <li><codeph>md5xor</codeph> - calculates the MD5 value of all rows, then performs an XOR
            over the MD5 values.</li>
        </ul></p>
    </body>
  </topic>
    <topic id="topic_ytw_2sp_zdb">
    <title>Addressing Failed Data Transfers</title>
    <body>
      <p>When <codeph>gpcopy</codeph> encounters errors and quits or is cancelled by the user, the
        currently-running copy operations on tables in the destination database are rolled back.
        Copy operations that have completed are not rolled back. </p>
      <p>If a non-fatal error occurs during the process of copying a table, or a table validation
        fails, <codeph>gpcopy</codeph> continues copying the other specified tables. </p>
      <p>After <codeph>gpcopy</codeph> completes, it displays a summary of the copy operations that
        were performed, and lists any tables that encountered errors or failed validation checks. If
        any errors occurred, the summary displays a modified <codeph>gpcopy</codeph> command that
        you can use to retry copying the failed tables. </p>
      <p>After resolving the issues that caused the copy operations to fail, you can run the
        provided command to copy the tables that failed in the previous <codeph>gpcopy</codeph>
        command. </p>
      <p>The <codeph>gpcopy</codeph> utility logs messages in log file
            <codeph>gpcopy_<varname>date</varname>.log</codeph> the <codeph>~/gpAdminLogs</codeph>
        directory on the master host. If you run multiple <codeph>gpcopy</codeph> commands on the
        same day, the utility appends messages to that day's log file. </p>
    </body>
  </topic>
  <topic id="topic_pyc_hpp_zdb">
    <title>Migrating Data Between Clusters that Share Hardware</title>
    <body>
      <p>In order to migrate data between two clusters on the same hardware, you should have enough
        free disk space to accommodate over 5 times the original data set. This enables you to
        maintain 2 full copies of the primary and mirror data sets (on the source and destination
        systems), plus the original backup data in ASCII format. </p>
      <p>If you attempt to migrate and find that you do not have enough free space, the
          <codeph>gpcopy</codeph> utility provides the <codeph>--truncate-source-after</codeph>
        option to help you migrate data from one cluster to another on the same hardware with only a
        minimum of free disk space. The <codeph>--truncate-source-after</codeph> option instructs
        the utility to truncate each source table after successfully copying the table data  to the
        destination cluster and validating the the copy succeeded.</p>
      <p>If you choose to use <codeph>--truncate-source-after</codeph>, consider the following:<ul
          id="ul_g5k_22q_zdb">
          <li>Back up all source data before using <codeph>gpcopy</codeph> with
              <codeph>--truncate-source-after</codeph>.</li>
          <li>Migrating data with <codeph>--truncate-source-after</codeph> still requires an amount
            of free disk space equal to the sum of the largest tables that you will migrate in a
            single batch using <codeph>gpcopy</codeph>. For example, with a <codeph>--jobs</codeph>
            setting of 5, you must ensure that you have free space equal to the sum of the 5 largest
            tables copied in the batch. The following query lists the largest 5 tables in your
            source system; modify the query as needed depending on the <codeph>--jobs</codeph>
            setting you intend to
            use:<codeblock>gpadmin=# SELECT n.nspname, c.relname, c.relstorage, pg_relation_size(c.oid)
FROM 
pg_class c JOIN pg_namespace n ON (c.relnamespace=n.oid)
JOIN pg_catalog.gp_distribution_policy p ON (c.oid = p.localoid)
WHERE
n.nspname NOT IN ('gpexpand', 'pg_bitmapindex', 'information_schema', 'gp_toolkit')
AND n.nspname NOT LIKE 'pg_temp_%%' AND c.relstorage &lt;> 'v'
ORDER BY 4 DESC LIMIT 5;
</codeblock></li>
          <li>Start both the source and destination clusters in restricted mode (<codeph>gpstart
              -R</codeph>) to ensure that no updates occur while executing
            <codeph>gpcopy</codeph>.</li>
          <li>While Greenplum Database 4.3.26 and later support migration with
              <codeph>gpcopy</codeph>, Greenplum Database 4.3.x does not include the
              <codeph>gpcopy</codeph> utility. You must manually copy the utility to your Greenplum
            Database 4.3.x
            installation:<codeblock>$ cp /usr/local/greenplum-db-5.8.0/bin/gpcopy /usr/local/greenplum-db-4.3.26.0/bin/</codeblock></li>
          <li>Execute <codeph>gpcopy</codeph> using the utility version installed on the source
            Greenplum Database system (source the <codeph>greenplum_path.sh</codeph> file for the
            source installation).</li>
          <li>You must use the <codeph>--validate</codeph> option with
              <codeph>--truncate-source-after</codeph> to ensure that data is successfully copied
            before source tables are truncated.<note>If you are migrating data from Greenplum 4.x to
              5.x, MD5 validation (<codeph>--validate md5xor</codeph>) will always fail. Use
                <codeph>--validate count</codeph> when migrating between major versions to validate
              by table row count.</note></li>
          <li>If you use <codeph>--truncate-source-after</codeph> to migrate data on shared
            hardware, also include the <codeph>--no-compression</codeph> option to avoid the
            overhead cost of compressing and uncompressing data that does not move across the
            network.</li>
          <li>Consider migrating only portions of the your data at a time, so that you can fully
            address table errors or validation failures that may occur during the copy
            operation.</li>
          <li>In general, keep in mind that using the <codeph>--truncate-source-after</codeph>
            option does not allow for an easy rollback to the source system to its original
            condition if errors occur or validation checks fail during the <codeph>gpcopy</codeph>
            operation. Table errors or validation failures during the <codeph>gpcopy</codeph>
            operation can leave some tables remaining in the source cluster, while other tables may
            be empty (having been truncated after being copied to the new cluster).</li>
        </ul></p>
      <p>For example:</p>
      <codeblock>gpcopy --source-host my_host --source-port 1234 --source-user gpuser \
--dest-host my_host --dest-port 1235 --dest-user gpuser --dbname database1 \
-truncate --analyze --validate count --no-compression</codeblock>
    </body>
  </topic>
</topic>
